{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qvieth/PhoTransciptor/blob/main/PhoTranscriptor_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMWkQn5rRCcd"
      },
      "outputs": [],
      "source": [
        "# --- Install the PyTorch stack ---\n",
        "print(\"Installing torch, torchvision, torchaudio...\")\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "# --- Install other required Python libraries, UPGRADING Gradio ---\n",
        "print(\"Installing transformers, accelerate, soundfile, librosa, gradio...\")\n",
        "!pip install transformers accelerate soundfile librosa gradio --upgrade\n",
        "\n",
        "# --- Install FFmpeg ---\n",
        "print(\"Installing FFmpeg...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq ffmpeg\n",
        "\n",
        "print(\"\\nInstallation steps complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import sys\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from functools import lru_cache\n",
        "import time\n",
        "\n",
        "MODEL_NAME = \"vinai/PhoWhisper-large\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CHUNK_LENGTH_S = 30\n",
        "\n",
        "LOCAL_MODEL_PATH = MODEL_NAME\n",
        "print(f\"Running on: {DEVICE}\")\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def load_model(model_source):\n",
        "    print(f\"Loading model: {model_source}...\")\n",
        "    progress = gr.Progress()\n",
        "    progress(0, desc=\"Loading model...\")\n",
        "    try:\n",
        "        pipe = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=model_source,\n",
        "            chunk_length_s=CHUNK_LENGTH_S,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        progress(1.0, desc=\"Model loaded successfully.\")\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return pipe\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error loading model: {e}\"\n",
        "        print(error_msg)\n",
        "        progress(1.0, desc=error_msg)\n",
        "        return None\n",
        "\n",
        "asr_pipeline = load_model(LOCAL_MODEL_PATH)\n",
        "\n",
        "def get_audio_duration(audio_path):\n",
        "    if not audio_path or not os.path.exists(audio_path):\n",
        "        return 0\n",
        "    try:\n",
        "        duration = librosa.get_duration(path=audio_path)\n",
        "        return duration\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not get duration for {audio_path}: {e}\")\n",
        "        try:\n",
        "            with sf.SoundFile(audio_path) as f:\n",
        "                duration = len(f) / f.samplerate\n",
        "                return duration\n",
        "        except Exception as sf_e:\n",
        "            print(f\"Warning: Soundfile also failed for {audio_path}: {sf_e}\")\n",
        "            return 0\n",
        "\n",
        "def transcribe_audio_for_blocks(audio_file_obj, progress=gr.Progress()):\n",
        "    if asr_pipeline is None:\n",
        "        return \"Error: ASR model is not loaded. Check console output.\", \"Status: Error - Model not loaded.\"\n",
        "    if audio_file_obj is None:\n",
        "        return \"Please upload an audio file.\", \"Status: Waiting for audio.\"\n",
        "\n",
        "    audio_filepath = audio_file_obj\n",
        "    print(f\"Received audio input, temp file at: {audio_filepath}\")\n",
        "\n",
        "    duration = get_audio_duration(audio_filepath)\n",
        "    duration_str = f\"{duration:.2f} seconds\" if duration > 0 else \"unknown duration\"\n",
        "    print(f\"Audio duration: {duration_str}\")\n",
        "\n",
        "    status_message_during_transcription = f\"Status: Transcribing {duration_str} of audio...\"\n",
        "    progress(0, desc=f\"Audio Duration: {duration_str}. Transcribing...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        transcription_result = asr_pipeline(audio_filepath)\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        progress(1.0, desc=\"Transcription Complete.\")\n",
        "        success_status_message = f\"Status: Transcription completed in {processing_time:.2f} seconds (Audio duration: {duration_str})\"\n",
        "        return transcription_result[\"text\"], success_status_message\n",
        "    except Exception as e:\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        error_message = f\"Transcription failed: {e}\"\n",
        "        print(f\"An error occurred during transcription: {e}\")\n",
        "        progress(1.0, desc=error_message)\n",
        "        failure_status_message = f\"Status: Transcription failed after {processing_time:.2f} seconds. Error: {e}\"\n",
        "        return error_message, failure_status_message\n",
        "\n",
        "# ✅ NEW: Save transcript to file\n",
        "def save_transcript_to_file(transcript_text, filename=\"transcript.txt\"):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcript_text)\n",
        "    return filename\n",
        "\n",
        "# ✅ NEW: Prepare download\n",
        "def prepare_download_file(transcript_text):\n",
        "    filename = \"transcript.txt\"\n",
        "    return save_transcript_to_file(transcript_text, filename)\n",
        "\n",
        "# UI strings\n",
        "title = \"PhoWhisper ASR\"\n",
        "description_markdown = f\"\"\"\n",
        "Upload a Vietnamese audio file to transcribe it using the PhoWhisper-large model ({MODEL_NAME}).\n",
        "<b>Running on:</b> {DEVICE}\n",
        "<b>Note:</b> Sau khi tạo transcript xong, một số người dùng phản ánh tình trạng lag khi dán vào Word nên mình đã bổ sung thêm 1 tính năng Download Transcript.\n",
        "<br>Khi transcript tạo xong, click chuột phải chỗ vị trí #KB ⇣ , chọn Lưu liên kết thành.../Save link as... để lưu transcript thành 1 file txt, từ file này copy vào word thì sẽ không bị lag.\n",
        "<br>HOẶC đơn giản hơn, sau khi bấm nút copy transcript, dán nội dung vào Notepad/GoogleDocs để xoá format ẩn, sau đó copy lại và dán vào Word thì sẽ không bị lag nữa.\n",
        "\"\"\"\n",
        "\n",
        "citation_bibtex = \"\"\"\n",
        "@inproceedings{PhoWhisper,\n",
        "   title     = {{PhoWhisper: Automatic Speech Recognition for Vietnamese}},\n",
        "   author    = {Thanh-Thien Le and Linh The Nguyen and Dat Quoc Nguyen},\n",
        "   booktitle = {Proceedings of the ICLR 2024 Tiny Papers track},\n",
        "   year      = {2024}\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "credits_and_citation_markdown = f\"\"\"\n",
        "# Credits & Citation\n",
        "\n",
        "## User Interface Development\n",
        "This interface was developed by Mr. Le Nguyen Nhu Anh (<a href=\"mailto:leyny036@mymail.unisa.edu.au\">leyny036@mymail.unisa.edu.au</a>), PhD Candidate at the University of South Australia.\n",
        "\n",
        "## ASR Model Citation\n",
        "If you use the underlying PhoWhisper model for your work, please cite the original authors:\n",
        "\n",
        "{citation_bibtex}\n",
        "\n",
        "Links:\n",
        "- Paper: <a href=\"https://openreview.net/pdf?id=qsif2awK2L\" target=\"_blank\">PhoWhisper (ICLR 2024)</a>\n",
        "- Model: <a href=\"https://huggingface.co/vinai/PhoWhisper-large\" target=\"_blank\">vinai/PhoWhisper-large</a>\n",
        "\"\"\"\n",
        "\n",
        "# --- Interface ---\n",
        "with gr.Blocks(title=title, theme=gr.themes.Soft()) as interface:\n",
        "    gr.Markdown(f\"<h1>{title}</h1>\")\n",
        "    gr.Markdown(description_markdown)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_input = gr.Audio(type=\"filepath\", label=\"Upload Vietnamese Audio File\")\n",
        "            transcribe_button = gr.Button(\"Transcribe Audio\")\n",
        "\n",
        "        with gr.Column():\n",
        "            transcription_output_textbox = gr.Textbox(\n",
        "                label=\"Transcription\",\n",
        "                lines=5,  # ✨ Adjusted to reduce interface lag\n",
        "                interactive=True,\n",
        "                placeholder=\"Transcription will appear here...\",\n",
        "                show_copy_button=True\n",
        "            )\n",
        "            status_textbox = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            # ✨ New: download file button and output\n",
        "            download_button = gr.Button(\"Download Transcript\")\n",
        "            download_file_output = gr.File(label=\"Download your transcript\")\n",
        "\n",
        "    gr.Markdown(credits_and_citation_markdown)\n",
        "\n",
        "    transcribe_button.click(\n",
        "        fn=transcribe_audio_for_blocks,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[transcription_output_textbox, status_textbox],\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    # ✨ Download action\n",
        "    download_button.click(\n",
        "        fn=prepare_download_file,\n",
        "        inputs=[transcription_output_textbox],\n",
        "        outputs=[download_file_output]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if asr_pipeline is None:\n",
        "        print(\"\\nApplication will not launch because the ASR Pipeline failed to load.\")\n",
        "    else:\n",
        "        interface.launch(share=True, debug=False)"
      ],
      "metadata": {
        "id": "g2lRoGw4RtVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}